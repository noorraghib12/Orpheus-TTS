  0%|                                                                                                                                                                                     | 0/6468 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/root/Orpheus-TTS/finetune/train.py", line 52, in <module>
    trainer.train()
  File "/usr/local/lib/python3.11/dist-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/transformers/trainer.py", line 2648, in _inner_training_loop
    self.optimizer.step()
  File "/usr/local/lib/python3.11/dist-packages/accelerate/optimizer.py", line 179, in step
    self.optimizer.step(closure)
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py", line 124, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py", line 485, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py", line 79, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py", line 236, in step
    has_complex = self._init_group(
                  ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py", line 176, in _init_group
    state["exp_avg"] = torch.zeros_like(
                       ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 44.45 GiB of which 26.62 MiB is free. Process 951147 has 44.41 GiB memory in use. Of the allocated memory 43.77 GiB is allocated by PyTorch, and 335.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
